Tasks
1. Take care of the missing data
-> We can handle missing data in multiple ways.
   a. Removing the records with missing data could be easiest option but that is not a good one as we lose data.
   b. Replacing missing data with some values. This is sometimes called imputing.
      We can replace missing value with either mean/median of the present values, value randomly selected from another record, value 
	  returned by another model. We can also use a default value depending on context. We have to remember that whatever logic we follow for imputing training
      data set, same logic needs to be followed for predicting/test dataset.
   
->Imputing or filling the missing data can be done in multiple ways
  a. Using Pandas DataFrame APIs
  b. Using sklearn.preprocessing.Imputer class
  

2. Handle categorical data
-> To handle categorical data we need to transform data to to enums. For that LableEncoder from sklearn can be used
   Since ML algorithms understand only numbers , they might consider enums in ascending or descending order, which would be wrong.
   Using OneHotEncoder which transforms a categorical independent variable into dummy variables.
   Thus making it useful in ML model.
   Categorical columns to be handled = Sex, pclass, Sibsp, Parch, Embarked
   
3. Feature engineering

	a. WasWithFamily?

		if SibSp + Parch > 0 then True

		else False

	b. HadBenefitOfParentalSupport?

	   if age < 20 and Parch > 0 then True

	   else: False

	c. HadSupportOfYoungSiblings?

	   Not Sure if this helps

	d. HadSpouseOnBoard? 

	   Not sure if this helps

	   if age > 18  and title does not include Master/Miss/Mlle then you might be married:

		   if SibSp == 1: 

			  then True

		   else

			  False

	e. KnewTheWayAroundInTitanic? If you embarked on Southampton then you have been on ship for almost a week compared to people embarking later, so you know the way around

	   if embrked from southampton then True

	   else False  
   
   
